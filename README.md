# ğŸ­ EduFocus - Sistema de Reconhecimento de EmoÃ§Ãµes

<div align="center">

![Python](https://img.shields.io/badge/Python-3.13-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.7.1-red.svg)
![CUDA](https://img.shields.io/badge/CUDA-11.8-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40-FF4B4B.svg)
![Accuracy](https://img.shields.io/badge/Accuracy-68.49%25-brightgreen.svg)

Sistema de anÃ¡lise de emoÃ§Ãµes faciais em tempo real usando Deep Learning, desenvolvido para monitorar o engajamento de alunos em ambientes educacionais.

[Demo](#-demo) â€¢ [InstalaÃ§Ã£o](#-instalaÃ§Ã£o) â€¢ [Uso](#-uso) â€¢ [Arquitetura](#-arquitetura) â€¢ [Resultados](#-resultados)

</div>

---

## ğŸ“‹ Sobre o Projeto

**EduFocus** Ã© um sistema de Deep Learning desenvolvido para automatizar a anÃ¡lise do engajamento dos alunos em tempo real atravÃ©s da interpretaÃ§Ã£o de expressÃµes faciais. O projeto utiliza visÃ£o computacional e processamento de imagens para detectar faces e classificar 7 emoÃ§Ãµes diferentes com alta precisÃ£o.

### Objetivo

Auxiliar professores a medir o engajamento de alunos em aulas remotas ou turmas grandes, fornecendo feedback em tempo real sobre as emoÃ§Ãµes dos estudantes atravÃ©s da anÃ¡lise de expressÃµes faciais.

### Principais Features

- **DetecÃ§Ã£o Precisa de Faces**: OpenCV DNN com ResNet-10 SSD
- **AnÃ¡lise de EmoÃ§Ãµes**: EfficientNet-B2 treinado em FER2013
- **Alta AcurÃ¡cia**: 68.49% de acurÃ¡cia no conjunto de validaÃ§Ã£o
- **MÃºltiplas Faces**: Detecta e analisa vÃ¡rias pessoas simultaneamente
- **Tempo Real**: Processamento frame-by-frame com GPU
- **Sistema de EstabilizaÃ§Ã£o**: Reduz flickering nas prediÃ§Ãµes
- **Interface Web**: AplicaÃ§Ã£o Streamlit interativa e responsiva
- **GPU Acelerado**: Suporte CUDA para processamento rÃ¡pido

### EmoÃ§Ãµes Detectadas

| EmoÃ§Ã£o | Emoji | Cor | Uso Educacional |
|--------|-------|-----|----------------|
| Feliz | ğŸ˜Š | Verde | Alto engajamento |
| Triste | ğŸ˜¢ | Azul | PossÃ­vel desinteresse |
| Raiva | ğŸ˜  | Vermelho | FrustraÃ§Ã£o |
| Surpresa | ğŸ˜² | Amarelo | Descoberta/Interesse |
| Medo | ğŸ˜¨ | Roxo | Ansiedade |
| Nojo | ğŸ¤¢ | Ciano | Desagrado |
| Neutro | ğŸ˜ | Cinza | AtenÃ§Ã£o passiva |

---

## Demo

### Interface Streamlit

A aplicaÃ§Ã£o web oferece duas funcionalidades principais:

1. **Upload de Imagem**: Analise fotos estÃ¡ticas
2. **Webcam em Tempo Real**: DetecÃ§Ã£o contÃ­nua via navegador

### Executar Demo Local

```bash
# Interface Web (Streamlit)
streamlit run app.py

# DetecÃ§Ã£o em Tempo Real (OpenCV)
python src/inference/real_time_improved.py
```

---

## InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10+
- CUDA 11.8+ (opcional, para GPU)
- Webcam (para detecÃ§Ã£o em tempo real)

### Passo a Passo

1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/seu-usuario/face-emotions-PI.git
cd face-emotions-PI
```

2. **Crie um ambiente virtual** (recomendado)
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Download automÃ¡tico de modelos**
Os arquivos necessÃ¡rios (modelo treinado e face detector) sÃ£o baixados automaticamente na primeira execuÃ§Ã£o do app.

---

## Uso

### 1. Interface Web (Streamlit)

```bash
streamlit run app.py
```

A interface oferece:
- **Upload de imagem**: Arraste e solte fotos para anÃ¡lise
- **Webcam em tempo real**: Acesso direto Ã  cÃ¢mera pelo navegador
- **HistÃ³rico de emoÃ§Ãµes**: Tabela com todas as detecÃ§Ãµes
- **Bounding boxes coloridas**: VisualizaÃ§Ã£o por emoÃ§Ã£o

### 2. DetecÃ§Ã£o em Tempo Real (OpenCV)

```bash
python src/inference/real_time_improved.py
```

Controles:
- **`q` ou `ESC`**: Sair
- **`s`**: Salvar screenshot
- **`r`**: Resetar histÃ³rico

### 3. Avaliar Modelo

```bash
python evaluate_model.py
```

Gera relatÃ³rio completo com:
- AcurÃ¡cia geral
- PrecisÃ£o, Recall e F1-Score por emoÃ§Ã£o
- Matriz de confusÃ£o

---

## Arquitetura

### Pipeline de Processamento

```
Imagem/VÃ­deo 
    â†“
DetecÃ§Ã£o de Faces (OpenCV DNN)
    â†“
ExtraÃ§Ã£o de ROI
    â†“
Preprocessamento (Resize, NormalizaÃ§Ã£o)
    â†“
ClassificaÃ§Ã£o de EmoÃ§Ã£o (EfficientNet-B2)
    â†“
EstabilizaÃ§Ã£o (Voting System)
    â†“
VisualizaÃ§Ã£o (Bounding Box + Label)
```

### Modelos Utilizados

#### 1. Face Detection
- **Modelo**: ResNet-10 SSD (OpenCV DNN)
- **Entrada**: Imagens 300x300
- **SaÃ­da**: Coordenadas de faces detectadas
- **Threshold**: 50% de confianÃ§a

#### 2. Emotion Recognition
- **Backbone**: EfficientNet-B2 (ImageNet pretrained)
- **Input Size**: 96x96 pixels
- **Classes**: 7 emoÃ§Ãµes
- **Output**: Probabilidades softmax

### Estrutura do Projeto

```
ProjetoPI/
â”œâ”€â”€ app.py                          # Interface Streamlit
â”œâ”€â”€ evaluate_model.py               # Script de avaliaÃ§Ã£o
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â”œâ”€â”€ README.md                       # DocumentaÃ§Ã£o
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                 # ConfiguraÃ§Ãµes do modelo
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py               # Dataset e data augmentation
â”‚   â”‚   â””â”€â”€ prepare_dataset.py       # PreparaÃ§Ã£o do FER2013
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ emotion_model.py         # Arquitetura CNN
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_emotions.py       # Treinamento principal
â”‚   â”‚   â””â”€â”€ mixup.py                 # Data augmentation (Mixup/CutMix)
â”‚   â””â”€â”€ inference/
â”‚       â””â”€â”€ real_time_improved.py   # DetecÃ§Ã£o em tempo real (OpenCV)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ download_face_detector.py   # Download do detector de faces
â”‚   â”œâ”€â”€ download_fer2013.py         # Download do dataset
â”‚   â””â”€â”€ verify_dataset.py           # VerificaÃ§Ã£o do dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/emotions/
â”‚   â”‚   â””â”€â”€ best.pth                 # Modelo treinado (97MB)
â”‚   â””â”€â”€ face_detector/
â”‚       â”œâ”€â”€ deploy.prototxt          # Arquitetura do detector
â”‚       â””â”€â”€ res10_300x300_ssd_*.caffemodel  # Pesos do detector
â””â”€â”€ data/
    â”œâ”€â”€ raw/emotions/                # Dataset original FER2013
    â””â”€â”€ processed/emotions/          # Dataset prÃ©-processado
        â”œâ”€â”€ train/                   # ~28,000 imagens
        â”œâ”€â”€ val/                     # ~3,500 imagens
        â””â”€â”€ test/                    # ~3,500 imagens
```

---

## Dataset

### FER2013 (Facial Expression Recognition 2013)

- **Fonte**: Kaggle Challenge
- **Tamanho**: ~35,000 imagens
- **ResoluÃ§Ã£o**: 48x48 pixels (grayscale)
- **DivisÃ£o**: 80% treino, 10% validaÃ§Ã£o, 10% teste

### Data Augmentation Aplicada

- **TransformaÃ§Ãµes GeomÃ©tricas**: RotaÃ§Ã£o, escala, shift
- **Horizontal Flip**: 50% de probabilidade
- **RuÃ­do e Blur**: Gaussian noise, motion blur
- **DistorÃ§Ãµes**: Grid distortion, elastic transform
- **Cor e IluminaÃ§Ã£o**: Brightness, contrast, hue, saturation
- **Dropout de Patches**: CoarseDropout
- **Mixup**: CombinaÃ§Ã£o de imagens (20% das batches)
- **Label Smoothing**: Îµ=0.1

---

## Resultados

### MÃ©tricas Gerais

| MÃ©trica | Valor |
|---------|-------|
| **AcurÃ¡cia de ValidaÃ§Ã£o** | 68.49% |
| **AcurÃ¡cia de Treino** | 57.85% |
| **Ã‰pocas Treinadas** | 21/30 |
| **Backbone** | EfficientNet-B2 |

### Performance por EmoÃ§Ã£o

As emoÃ§Ãµes sÃ£o classificadas com diferentes nÃ­veis de confianÃ§a. Para mÃ©tricas detalhadas por emoÃ§Ã£o, execute:
```bash
python evaluate_model.py
```

### TÃ©cnicas de OtimizaÃ§Ã£o

- **Backbone**: EfficientNet-B2 (pretrained no ImageNet)
- **Input Size**: 96x96 pixels
- **Batch Size**: 24
- **Learning Rate**: 0.0001
- **RegularizaÃ§Ã£o**: Dropout (0.4), Weight Decay (0.0001)
- **Loss Function**: Label Smoothing Cross Entropy (Îµ=0.1)
- **Optimizer**: AdamW com Cosine Annealing Scheduler
- **Data Augmentation**: Mixup (Î±=0.2, prob=0.5)
- **Early Stopping**: PaciÃªncia de 10 Ã©pocas
- **Ã‰pocas MÃ¡ximas**: 30

---

## Deploy

### Streamlit Cloud (Recomendado)

1. **FaÃ§a push do cÃ³digo para GitHub**
2. **Acesse** [streamlit.io/cloud](https://streamlit.io/cloud)
3. **Conecte seu repositÃ³rio**
4. **Configure**:
   - Main file: `app.py`
   - Python version: 3.10
5. **Deploy automÃ¡tico!**

O modelo e face detector sÃ£o baixados automaticamente na primeira execuÃ§Ã£o.

### Requisitos de Hardware

- **MÃ­nimo**: CPU, 2GB RAM
- **Recomendado**: GPU (CUDA), 4GB RAM
- **Cloud**: Funciona em tier gratuito do Streamlit Cloud

---

## Tecnologias Utilizadas

- **Deep Learning**: PyTorch 2.7.1
- **VisÃ£o Computacional**: OpenCV 4.x
- **Backbone**: EfficientNet-B2 (timm)
- **Interface**: Streamlit 1.40
- **Data Augmentation**: Albumentations
- **MÃ©tricas**: scikit-learn
- **Processamento**: NumPy, Pandas
- **Download**: gdown (Google Drive)

---

## Equipe

**Grupo 1 - EduFocus**
- Projeto Integrador - Senac
- Curso: Deep Learning
- PerÃ­odo: 2025

---

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## PrÃ³ximos Passos

- [ ] Adicionar detecÃ§Ã£o de emoÃ§Ãµes em vÃ­deos gravados
- [ ] Implementar dashboard de analytics
- [ ] Exportar relatÃ³rios em PDF

---

<div align="center">

**Desenvolvido com â¤ï¸ para melhorar a educaÃ§Ã£o**

[Reportar Bug](https://github.com/seu-usuario/face-emotions-PI/issues) â€¢ [Solicitar Feature](https://github.com/seu-usuario/face-emotions-PI/issues)

</div>